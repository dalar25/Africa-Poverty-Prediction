{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Ethiopia = pd.read_csv(\"ethiopia_df.csv\")\n",
    "Malawi = pd.read_csv(\"malawi_df.csv\")\n",
    "Mali = pd.read_csv(\"mali_df.csv\")\n",
    "Nigeria = pd.read_csv(\"nigeria_df.csv\")\n",
    "\n",
    "Ethiopia = Ethiopia.drop('Unnamed: 0', axis=1)\n",
    "Malawi = Malawi.drop('Unnamed: 0', axis=1)\n",
    "Mali = Mali.drop('Unnamed: 0', axis=1)\n",
    "Nigeria = Nigeria.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "imageVals = list(Ethiopia['Image'].values) + list(Malawi['Image'].values) + list(Mali['Image'].values) + list(Nigeria['Image'].values)\n",
    "PPPvals = list(Ethiopia['PPP'].values) + list(Malawi['PPP'].values) + list(Mali['PPP'].values) + list(Nigeria['PPP'].values)\n",
    "PPPvals = [int(i*1000+.5) for i in PPPvals]\n",
    "\n",
    "data = []\n",
    "for i in range(len(PPPvals)):\n",
    "    data.append([imageVals[i],PPPvals[i]])\n",
    "\n",
    "data = pd.DataFrame(data, columns=['Image', 'PPP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11810\n",
      "10363\n",
      "12908\n",
      "12340\n",
      "47421\n"
     ]
    }
   ],
   "source": [
    "print(sum(val < 1500 for val in PPPvals))\n",
    "print(sum(1500 <= val < 2000 for val in PPPvals))\n",
    "print(sum(2000 <= val < 3000 for val in PPPvals))\n",
    "print(sum(3000 <= val for val in PPPvals)) #70-30 and 75-25 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "PPPclassification = []\n",
    "for val in PPPvals:\n",
    "    if val<1500:\n",
    "        PPPclassification.append(0) \n",
    "    elif 1500<val<2000:\n",
    "        PPPclassification.append(1) \n",
    "    elif 2000<val<3000:\n",
    "        PPPclassification.append(2) \n",
    "    else:\n",
    "        PPPclassification.append(3) \n",
    "\n",
    "data['Class'] = PPPclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "imgArrays = []\n",
    "\n",
    "#count=0\n",
    "\n",
    "for img in imageVals:\n",
    "    \n",
    "    array = plt.imread(img, format=None)\n",
    "\n",
    "    imgList = []\n",
    "    for i in array:\n",
    "        list1 = []\n",
    "        for j in i:\n",
    "            list2 = [j[0],j[1],j[2]]\n",
    "            list1.append(list2)\n",
    "        imgList.append(list1)\n",
    "    array = imgList\n",
    "    imgArrays.append(array)\n",
    "'''\n",
    "    count+=1\n",
    "    if count == 100:\n",
    "        break\n",
    "'''\n",
    "imgArrays = np.array(imgArrays)\n",
    "classes = np.array(data['Class'].values)\n",
    "\n",
    "%store imgArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k0/4j_3xmsj5318lx3sbl7l72tw80k58g/T/ipykernel_22085/2058161860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r imgArrays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "%store -r imgArrays\n",
    "classes = np.array(data['Class'].values)\n",
    "\n",
    "\n",
    "X = imgArrays\n",
    "y = classes #y = classes[0:100]\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=2)\n",
    "'''\n",
    "y_train_encoded = []\n",
    "for i in y_train:\n",
    "    temp = [0,0,0,0]\n",
    "    temp[i]=1\n",
    "    y_train_encoded.append(temp)\n",
    "\n",
    "\n",
    "y_test_encoded = []\n",
    "for i in y_test:\n",
    "    temp = [0,0,0,0]\n",
    "    temp[i]=1\n",
    "    y_test_encoded.append(temp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) #activation function relu takes the sum of all inputs, but if it is negative, the output is 0\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='relu')) #Dense: all previous nodes connected to new nodes\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu')) \n",
    "model.add(layers.Dense(1))\n",
    "#model.add(layers.Activation('softmax')) #softmax used with several classes and it gives probabilities for each class\n",
    "\n",
    "#add dropout which makes sure some of the lines are not activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                3686416   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,743,297\n",
      "Trainable params: 3,743,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 15:55:22.471741: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 15:55:22.472756: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 75 samples, validate on 25 samples\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 14s 191ms/step - loss: 3.7496 - val_loss: 0.7902\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 12s 165ms/step - loss: 0.6104 - val_loss: 0.4793\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 13s 169ms/step - loss: 0.4477 - val_loss: 0.4904\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 12s 164ms/step - loss: 0.4879 - val_loss: 0.4363\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 13s 168ms/step - loss: 0.3925 - val_loss: 0.5019\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 12s 162ms/step - loss: 0.4272 - val_loss: 0.4962\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 13s 170ms/step - loss: 0.4623 - val_loss: 0.4029\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 12s 166ms/step - loss: 0.3792 - val_loss: 0.4196\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 13s 167ms/step - loss: 0.4321 - val_loss: 0.3966\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 12s 163ms/step - loss: 0.3789 - val_loss: 0.4157\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "#model.compile(optimizer='adam',\n",
    "              #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              #metrics=['accuracy'])\n",
    "\n",
    "#y_test_encoded = np.array(y_test_encoded)\n",
    "#y_train_encoded = np.array(y_train_encoded)\n",
    "#X_train = np.array(X_train)\n",
    "#X_test = np.array(X_test)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "#history = model.fit(X_train, y_train_encoded, epochs=10, \n",
    "                    #validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "listY_test = [int(i) for i in y_test]\n",
    "preds = [round(float(i)) for i in list(model.predict(X_test))]\n",
    "numCorrect = 0\n",
    "for i in range(len(listY_test)):\n",
    "    if listY_test[i]==preds[i]:\n",
    "        numCorrect+=1\n",
    "print(numCorrect/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/shap/explainers/tf_utils.py:28: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dalar25/opt/anaconda3/envs/tf/lib/python3.7/site-packages/shap/explainers/_deep/deep_tf.py:608: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "background = X_train[np.random.choice(X_train.shape[0], 10, replace=False)]\n",
    "# DeepExplainer to explain predictions of the model\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "# compute shap values\n",
    "shap_values = explainer.shap_values(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(\n",
    "#list(model.predict(X_train[0:1])).index(max(list(model.predict(X_train[0:1])))))\n",
    "\n",
    "print(model.predict(X_train[0:1]).tolist()[0].index(max(model.predict(X_train[0:1]).tolist()[0])))\n",
    "\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "shap_values = explainer.shap_values(X_test[0:11])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9e020127372726f3582a6156abdace9d2ab1400e9558d7eede7b2407d3ced0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
